{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trDwCVXRy-rn"
   },
   "source": [
    "Develop an advanced support ticket categorization system that accurately classifies incoming tickets, assigns relevant tags based on their content, implements mechanisms and generate the first response based on the sentiment for prioritizing tickets for prompt resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bonUQGu23RK"
   },
   "source": [
    "## **Installing and Importing Necessary Libraries and Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSZp9UgqNVS4"
   },
   "outputs": [],
   "source": [
    "# for loading and manipulating data.\n",
    "# try:\n",
    "#   import pandas as pd\n",
    "# except:\n",
    "#   pip uninstall numpy\n",
    "#   pip install numpy==1.15.1\n",
    "#   import pandas as pd\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "# # for time computations.\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0rHx0ZC5Jbv",
    "outputId": "8719d476-0c08-40ed-ee54-040293b62675"
   },
   "outputs": [],
   "source": [
    "# Installation for GPU llama-cpp-python.\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrU246OBS0MP"
   },
   "outputs": [],
   "source": [
    "# Importing the Llama class from the llama_cpp module.\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awsKQRs-OYo8"
   },
   "outputs": [],
   "source": [
    "# For downloading the models from HF Hub.\n",
    "# !pip install huggingface_hub==0.20.3 pandas==1.5.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0x29JGHMqD74"
   },
   "outputs": [],
   "source": [
    "# Function to download the model from the Hugging Face model hub.\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Importing the json module.\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTpWESc53dL9"
   },
   "source": [
    "## **Loading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksv9hSCR4BM_"
   },
   "outputs": [],
   "source": [
    "# Loading the data into df\n",
    "df = pd.read_csv(\"Support_ticket_text_data_mid_term.csv\")\n",
    "\n",
    "# Creating copy of 'df' in the variable data\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8qUEOcQ3j5q"
   },
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3YXcM8G3ljS"
   },
   "source": [
    "### Checking the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bNOTBqaNVG4j",
    "outputId": "784148c6-f8d9-4952-f304-fdc2ffa02b31"
   },
   "outputs": [],
   "source": [
    "# first 5 rows of the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UO3pFis3rDj"
   },
   "source": [
    "### Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fLXRyDA4m3S",
    "outputId": "3fd53474-1810-4e37-f7b5-4deb76517c88"
   },
   "outputs": [],
   "source": [
    "# shape of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4g6kMnPxlePH"
   },
   "outputs": [],
   "source": [
    "# There are 21 rows and 2 columns present in this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i1EB_O-3tJp"
   },
   "source": [
    "### Checking the missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rtx1knap5wRt",
    "outputId": "575a3428-73f9-4765-e18b-610803f77b80"
   },
   "outputs": [],
   "source": [
    "# Missing values in data\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mPMqAiCliP1"
   },
   "outputs": [],
   "source": [
    "# From the above output we identify there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qP5KTLo3OOC"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWvf3R3An5K4"
   },
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF2F_YO_qGtV"
   },
   "outputs": [],
   "source": [
    "# model name and model base name\n",
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "95b7bcbdc30244049555c2b415ba1ea9",
      "831283f977ef4f159a1210f2f48b02f7",
      "8f0551fc12b544ddb62ca4a4c0112caf",
      "ec226f1976e44fba83663baa01c9b03a",
      "47720fca238f4068901cb2c9d0b5d886",
      "f5e31abeba5a4b0a812d80d063d7313f",
      "4ba79b450f12494a901b3c42e3b46609",
      "a55f6b647d874c799e9ef7dcd4ade305",
      "d159ee51bca14573bad77dea32b885f7",
      "756fd6ded4f24c83800c007c5c05745e",
      "d3c2fa17a93e42a3b6440e38c3630c35"
     ]
    },
    "id": "Uk2q7vrc_TrO",
    "outputId": "ff2bfbeb-55a4-46e2-c8d6-f8d04c451a1a"
   },
   "outputs": [],
   "source": [
    "# Declaring repo_id and filename\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name_or_path, # repo_id = model_name_or_path\n",
    "    filename=model_basename # filename = model_basename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wI_T-0DWXRtD",
    "outputId": "7b12343d-a388-4697-cdf5-129aadc08a45"
   },
   "outputs": [],
   "source": [
    "# Defining the llm model - Llama (Run using GPU)\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=1024, # Context window\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8FxB-MBen3w"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PibZOe6aegGe"
   },
   "outputs": [],
   "source": [
    "# defining a function to parse the JSON output from the model\n",
    "def extract_json_data(json_str):\n",
    "    try:\n",
    "        # Find the indices of the opening and closing curly braces\n",
    "        json_start = json_str.find('{')\n",
    "        json_end = json_str.rfind('}')\n",
    "\n",
    "        if json_start != -1 and json_end != -1:\n",
    "            extracted_category = json_str[json_start:json_end + 1]  # Extract the JSON object\n",
    "            data_dict = json.loads(extracted_category)\n",
    "            return data_dict\n",
    "        else:\n",
    "            print(f\"Warning: JSON object not found in response: {json_str}\")\n",
    "            return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le80Djip27mc"
   },
   "source": [
    "## **Task 1: Ticket Categorization and Returning Structured Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2opKxTRX3Ksw"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzdh6COH_615"
   },
   "outputs": [],
   "source": [
    "# Defining the response funciton for Task 1.\n",
    "def response_1(prompt,ticket):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=10, # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01, # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4fvrtrB3P_G"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 1\n",
    "prompt_1 = \"\"\"\n",
    "   As an AI, your job is to categorize IT support tickets. \n",
    "   Please label each ticket as either a Hardware Issue, Data Recovery, or Technical Issue. \n",
    "   Your response should be in the format: {\"category\": \"Hardware Issues\"}, {\"category\": \"Data Recovery\"}, or {\"category\": \"Technical Issues\"}. \n",
    "   Keep your output simple and accurate. Ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afxdh6opkyfj"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UinALS1l3XjW",
    "outputId": "6b2f293c-5517-44d4-fa51-eab3211bea29"
   },
   "outputs": [],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text \n",
    "start = time.time()\n",
    "data_1['model_response'] = data_1['support_ticket_text'].apply(lambda x: response_1(prompt_1, x))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bo0YlHPXAJfP",
    "outputId": "984dd8d6-7ea9-4465-8420-d2dc38329428"
   },
   "outputs": [],
   "source": [
    "# Time taken for model to return output\n",
    "print(\"Time taken:\", round((end-start)),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "pHn-R-fx31Uq",
    "outputId": "9a3e048a-f8a7-4128-f868-5efe0638b396"
   },
   "outputs": [],
   "source": [
    "# Initial model output\n",
    "data_1['model_response'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbHTOL494CkV",
    "outputId": "be4f2e67-376d-433c-dabf-0ef97f1d877c"
   },
   "outputs": [],
   "source": [
    "# Displaying the support ticket text\n",
    "i = 6\n",
    "print(data_1.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB9h31T54H4F",
    "outputId": "736c9af9-d6ea-4815-b6c0-5248246cf93a"
   },
   "outputs": [],
   "source": [
    "# Model output\n",
    "print(data_1.loc[i, 'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "PLjf4Kgu41oJ",
    "outputId": "9e433b3d-d28b-4f2f-8ba9-139ac66ca161"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_1['model_response_parsed'] = data_1['model_response'].apply(extract_json_data)\n",
    "data_1['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "OXi7nOzyeGdK",
    "outputId": "af18fa55-045c-40a8-8728-e73115091779"
   },
   "outputs": [],
   "source": [
    "# Model output after extracting JSON data\n",
    "data_1['model_response_parsed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pnivjGUcUONC",
    "outputId": "31da8a60-7af0-4d0d-f2bd-9ef154bcdee1"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_1 = pd.json_normalize(data_1['model_response_parsed'])\n",
    "model_response_parsed_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "V67nKkfUUd1c",
    "outputId": "df9395c3-07ff-4727-f8f9-b4b5d33678bb"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_1 = pd.concat([data_1, model_response_parsed_df_1], axis=1)\n",
    "data_with_parsed_model_output_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dHxzez70U0Dv",
    "outputId": "7d2f6a50-6c02-492e-efa4-aa443ed9dd36"
   },
   "outputs": [],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_1 = data_with_parsed_model_output_1.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z795llV0elBQ"
   },
   "source": [
    "## **Task 2: Creating Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWlFOeCFf5Zx"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSflU6-CBk29"
   },
   "outputs": [],
   "source": [
    "def response_2(prompt,ticket,category):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      Category: {category}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=1024,  # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01,  # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kODQ_X5Vf7gJ"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 2\n",
    "prompt_2 = \"\"\"\n",
    "   As an AI, your task is to label IT support tickets with relevant tags. \n",
    "   Please identify the most appropriate keywords and include them in your response. \n",
    "   Your output should be formatted as follows: {\"tags\": [\"Wifi\", \"Data Loss\", \"Connection Issues\", \"Battery\"]}.\n",
    "   Keep your output simple and accurate. Ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlnUmTSKlD-O"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEQu4_lUgcdW",
    "outputId": "23d44985-4d9b-4fda-e187-682cc39a55b1"
   },
   "outputs": [],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text\n",
    "start = time.time()\n",
    "data_2[\"model_response\"]=final_data_1[['support_ticket_text','category']].apply(lambda x: response_2(prompt_2, x[0],x[1]),axis =1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GeduRusM1i3",
    "outputId": "3279ab2e-ce4b-4fbb-b15a-4a6588334b4a"
   },
   "outputs": [],
   "source": [
    "# Time taken for model to generate output\n",
    "print(\"Time taken:\",round((end-start)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "y023-XNxgpYd",
    "outputId": "55186f07-4f48-47b1-cae9-d59aacea7539"
   },
   "outputs": [],
   "source": [
    "# Initial model output\n",
    "data_2['model_response'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqOM7mntgsJ6",
    "outputId": "2eeffa7e-9160-41d4-91c3-d032e65e99c2"
   },
   "outputs": [],
   "source": [
    "# Support ticket text\n",
    "i = 0\n",
    "print(data_2.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IayJkEP1gr96",
    "outputId": "d38724c8-9f39-48d5-ca25-ce4b790e8a90"
   },
   "outputs": [],
   "source": [
    "# Model output\n",
    "print(data_2.loc[i,'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8CTPgPQhKcx"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_2['model_response_parsed'] = data_2['model_response'].apply(extract_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "3om_9wk4W8_l",
    "outputId": "1ae16d04-2eec-47a0-9800-c3177441a8df"
   },
   "outputs": [],
   "source": [
    "# Model output after extracting JSON data\n",
    "data_2[\"model_response_parsed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6PAke663hN3T",
    "outputId": "0453f9db-9b70-4ae7-f5df-e010eb490545"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_2 = pd.json_normalize(data_2['model_response_parsed'])\n",
    "model_response_parsed_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "aXJqZgh-hP4G",
    "outputId": "5edba8bb-6e2f-41cd-a359-eb22a4c620bc"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_2 = pd.concat([data_2, model_response_parsed_df_2], axis=1)\n",
    "data_with_parsed_model_output_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vsT9xR1FhSRZ",
    "outputId": "b76c8454-befa-42e4-9b4f-b0636b9944b0"
   },
   "outputs": [],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_2 = data_with_parsed_model_output_2.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "4UAvaviZhUW4",
    "outputId": "1efe4dbf-2d70-4aad-9286-80e5acf1e0e6"
   },
   "outputs": [],
   "source": [
    "# Checking the value counts of Category column\n",
    "final_data_2['tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NybVxPKS8k3"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "final_data_2 = pd.concat([final_data_2,final_data_1[\"category\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Kt24BSz6THBr",
    "outputId": "0718e606-5dd4-4ea1-c819-6bf722cbe2f4"
   },
   "outputs": [],
   "source": [
    "# viewing newly updated dataframe\n",
    "final_data_2 = final_data_2[[\"support_tick_id\",\"support_ticket_text\",\"category\",\"tags\"]]\n",
    "final_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdwE7rguh8sD"
   },
   "source": [
    "## **Task 3: Assigning Priority and ETA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FS158JYiUXY"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_3 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHjSvP9maGFt"
   },
   "outputs": [],
   "source": [
    "# Function created to generate an output from the model\n",
    "def response_3(prompt,ticket,category,tags):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      Category: {category}\n",
    "      Tags: {tags}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=20,   # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01,  # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUHUh2mRiUUK"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 3\n",
    "prompt_3 = \"\"\"\n",
    "    As an AI, your task is to determine the priority and estimated time to resolve (ETA) for IT support tickets. \n",
    "    Consider the severity of the issue, the time needed for resolution, and customer satisfaction. \n",
    "    Your response should be in the format: {\"priority\": \"High\", \"eta\": \"2 Days\"}.\n",
    "    Keep your output simple and accurate. Ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VZ1BUwslKHD"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC2Ygg4AiUR6",
    "outputId": "291e07a9-73fe-47e4-cad0-05986f000652"
   },
   "outputs": [],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text  \n",
    "start = time.time()\n",
    "data_3['model_response'] = final_data_2[['support_ticket_text','category','tags']].apply(lambda x: response_3(prompt_3, x[0],x[1],x[2]),axis=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXnus6Akhmr8",
    "outputId": "d6b7cb3c-9f36-47a1-b4d0-a047074ab6da"
   },
   "outputs": [],
   "source": [
    "# Time taken for model to generate output\n",
    "print(\"Time taken:\",round((end-start)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "LsvGelDZiUPL",
    "outputId": "68974f0b-5470-4d33-e25e-4470297b8647",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initial model output\n",
    "data_3['model_response'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_iOXhT1iUMd",
    "outputId": "e1c51f79-c6fe-4566-c02d-9652c86717e4"
   },
   "outputs": [],
   "source": [
    "# Support ticket text\n",
    "i = 3\n",
    "print(data_3.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlqV49CeiUJz",
    "outputId": "463d1b6a-536b-41c2-80a5-21975a1aadf0"
   },
   "outputs": [],
   "source": [
    "# Model output\n",
    "print(data_3.loc[i,'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "h1F87rEpm70v",
    "outputId": "ccb9f6cc-a68d-4e96-8d0d-88b1f2ed01df"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_3['model_response_parsed'] = data_3['model_response'].apply(extract_json_data)\n",
    "data_3['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "BGLu4BJEnDQq",
    "outputId": "23279659-3287-492a-879c-dbb22386651b"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_3 = pd.json_normalize(data_3['model_response_parsed'])\n",
    "model_response_parsed_df_3.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "4x7VEKDcnL11",
    "outputId": "a4bcbe82-0a98-4dcb-a23e-bc00a5c243b5"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_3 = pd.concat([data_3, model_response_parsed_df_3], axis=1)\n",
    "data_with_parsed_model_output_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gz8WprxNnONN",
    "outputId": "7b187caf-df51-4d7f-8fec-e72f1d07f939"
   },
   "outputs": [],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_3 = data_with_parsed_model_output_3.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3Kmwtwvj_NO"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "final_data_3 = pd.concat([final_data_3,final_data_2[[\"category\",\"tags\"]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVa9DmktkL-x"
   },
   "outputs": [],
   "source": [
    "# Creating new dataframe\n",
    "final_data_3 = final_data_3[[\"support_tick_id\",\"support_ticket_text\",\"category\",\"tags\",\"priority\",\"eta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "da_W2ybekZHD",
    "outputId": "28ac0f7f-bf10-4b23-d56b-7556548e17a5"
   },
   "outputs": [],
   "source": [
    "# viewing newly updated dataframe\n",
    "final_data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7m73qRcne4g"
   },
   "source": [
    "## **Task 4 - Creating a Draft Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDe0fY0tnpCS"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_4 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czJxKYmGlG98"
   },
   "outputs": [],
   "source": [
    "# Function to generate output from the model\n",
    "def response_4(prompt,ticket,category,tags,priority,eta):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      Category : {category}\n",
    "      Tags : {tags}\n",
    "      Priority: {priority}\n",
    "      ETA: {eta}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=1024,  # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01,  # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "\n",
    "    return temp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CYnMUZUnqkf"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 4\n",
    "prompt_4 = \"\"\"\n",
    "    As an AI, your task is to draft a response for IT support tickets. \n",
    "    Consider customer satisfaction, the severity of the issue, and the company's responsibility. \n",
    "    Your response should be in the format: {\"response\": \"This is a draft response\"}. \n",
    "    Ensure your response is empathetic, professional, helpful, and concise.\n",
    "    Please ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2iYQuTPmcyA"
   },
   "source": [
    "**Note** : For this task, we will not be using the *`extract_json_data`* function. Hence, the output from the model should be a plain string and not a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3UBRIwcnqg8",
    "outputId": "59fa344a-f965-4fc6-c68d-14e5b2eaf302"
   },
   "outputs": [],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text \n",
    "start = time.time()\n",
    "data_4['model_response'] = final_data_3[['support_ticket_text','category','tags','priority','eta']].apply(lambda x: response_4(prompt_4, x[0],x[1],x[2],x[3],x[4]),axis=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDtIp9Hmlf9l",
    "outputId": "960cacae-a55a-48f3-e332-9f630cc3cb1a"
   },
   "outputs": [],
   "source": [
    "# Time taken for output to be generated by model\n",
    "print(\"Time taken:\", round((end-start)),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "PyIBbCkcnqeY",
    "outputId": "a556d4c7-2975-441e-c7b1-e020ee198890"
   },
   "outputs": [],
   "source": [
    "# Initial model output\n",
    "data_4['model_response'].head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWkqPHtinqcD",
    "outputId": "1436c95b-f16f-4b38-b184-ca2c23570689"
   },
   "outputs": [],
   "source": [
    "# Support ticket text\n",
    "i = 2\n",
    "print(data_4.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uPa8jt8nqZq",
    "outputId": "49410c75-9ef3-404f-946e-b15a63aade61"
   },
   "outputs": [],
   "source": [
    "# Model output\n",
    "print(data_4.loc[i,'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "MQ5FR7Rw2Lg-",
    "outputId": "4a5b44e7-8698-42da-e69e-0d518a06d4e9"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_4['model_response_parsed'] = data_4['model_response'].apply(extract_json_data)\n",
    "data_4['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "RtNaRvtt2Lg-",
    "outputId": "45b0fcfa-c5fc-48c2-ea48-98ca9af23877"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_4 = pd.json_normalize(data_4['model_response_parsed'])\n",
    "model_response_parsed_df_4.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKlPGXvqpcZ0"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "final_data_4 = pd.concat([final_data_3,model_response_parsed_df_4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-azDlrGegrxL"
   },
   "outputs": [],
   "source": [
    "# Renaming the dataframe\n",
    "final_data_4.rename(columns={\"model_response_parsed\":\"response\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qHgTohqhhLMp",
    "outputId": "96201c75-615c-4f21-8ff1-7f982ea39990"
   },
   "outputs": [],
   "source": [
    "# Viewing newly updated dataframe\n",
    "final_data_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQznlJqM2gSk"
   },
   "source": [
    "## **Model Output Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb0BE-W20_0K"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe of task 4\n",
    "final_data = final_data_4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "txX3gIQ9WZtD",
    "outputId": "b9b0787f-1768-455b-d76f-863bef15c93a"
   },
   "outputs": [],
   "source": [
    "# Value counts of category\n",
    "final_data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHvAlMpMh7Un"
   },
   "source": [
    "The model output for **category**:\n",
    "> \"Technical Issues\" for 8 tickets\n",
    "\n",
    "> \"Hardware Issues\" for 7 tickets\n",
    "\n",
    "> \"Data Recovery\" for 6 tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "lf-BVS4I2nxJ",
    "outputId": "99182401-e6a7-452a-cd8a-f47ef65a7fda"
   },
   "outputs": [],
   "source": [
    "# Value counts of priority\n",
    "final_data[\"priority\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf6HfjCAiQjN"
   },
   "source": [
    "The model output for **priority** of:\n",
    "\n",
    "> \"High\" to 19 tickets\n",
    "\n",
    "> \"Medium\" to 2 tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "hIkoCfUJ2ntq",
    "outputId": "59495f0b-4953-4c42-bde6-5338a05b3566"
   },
   "outputs": [],
   "source": [
    "# Value counts of ETA\n",
    "final_data[\"eta\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXZR34Z5ieEW"
   },
   "source": [
    "The model output for **ETA** of:\n",
    "> \"3 Days\" to 12 tickets\n",
    "\n",
    "> \"1 Day\" to 9 tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6sgaBLR6t-j"
   },
   "source": [
    "Let's dive in a bit deeper here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "rxtC6q6V6ZSR",
    "outputId": "daa5861e-608b-4cd8-829d-93cdf10d833d"
   },
   "outputs": [],
   "source": [
    " # Group by data with regard to categories and ETA.\n",
    "final_data.groupby(['category', 'eta']).support_tick_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MIcWd2ui0CZ"
   },
   "source": [
    "> Most \"Data Recovery\" tickets are estimated by the model to be resolved in \"3 Days\".\n",
    "\n",
    "> Most \"Hardware Issues\" tickets are estimated by the model to be resovled in \"3 Days\".\n",
    "\n",
    "> Most \"Technical Isses\" tickets are estimated by the model to be resovled in \"1 Day\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "9ge5lUJiMjjP",
    "outputId": "d2cfe1ac-a741-49ba-fc34-4ffd90b28dd1"
   },
   "outputs": [],
   "source": [
    "# Final_data(output) generated by model.\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpevKeiDiVuJ"
   },
   "source": [
    "## **Actionable Insights and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aE2sFkQluiC"
   },
   "source": [
    "**Insights:**\n",
    "> A detailed company information in the prompts provide better model output.\n",
    "\n",
    "> Adjust priority levels to align with your business's actual capabilities.\n",
    "\n",
    "> Curating responses to a specific business by adjusting prompts or outputs.\n",
    "\n",
    "> Adjust or expand categories to match your business's support needs. \n",
    "\n",
    "> Overall, The model's estimation of resolution times aligns with real-world scenarios.\n",
    "\n",
    "**Recommendations:**\n",
    "> Fine-tune the model with your company's data or profile for an improved performance.\n",
    "\n",
    "> Adjust \"priority\" of support tickets to reflect priorities the business can actually facilitate.\n",
    "\n",
    "> Need to evaluate on the format of responses with regard to the mail/response delivery methods.\n",
    "\n",
    "> Require a thorough test of the model with actual data before implementation."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "47720fca238f4068901cb2c9d0b5d886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ba79b450f12494a901b3c42e3b46609": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "756fd6ded4f24c83800c007c5c05745e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "831283f977ef4f159a1210f2f48b02f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5e31abeba5a4b0a812d80d063d7313f",
      "placeholder": "​",
      "style": "IPY_MODEL_4ba79b450f12494a901b3c42e3b46609",
      "value": "mistral-7b-instruct-v0.2.Q6_K.gguf: 100%"
     }
    },
    "8f0551fc12b544ddb62ca4a4c0112caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a55f6b647d874c799e9ef7dcd4ade305",
      "max": 5942065440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d159ee51bca14573bad77dea32b885f7",
      "value": 5942065440
     }
    },
    "95b7bcbdc30244049555c2b415ba1ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_831283f977ef4f159a1210f2f48b02f7",
       "IPY_MODEL_8f0551fc12b544ddb62ca4a4c0112caf",
       "IPY_MODEL_ec226f1976e44fba83663baa01c9b03a"
      ],
      "layout": "IPY_MODEL_47720fca238f4068901cb2c9d0b5d886"
     }
    },
    "a55f6b647d874c799e9ef7dcd4ade305": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d159ee51bca14573bad77dea32b885f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3c2fa17a93e42a3b6440e38c3630c35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec226f1976e44fba83663baa01c9b03a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_756fd6ded4f24c83800c007c5c05745e",
      "placeholder": "​",
      "style": "IPY_MODEL_d3c2fa17a93e42a3b6440e38c3630c35",
      "value": " 5.94G/5.94G [00:35&lt;00:00, 247MB/s]"
     }
    },
    "f5e31abeba5a4b0a812d80d063d7313f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
