{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trDwCVXRy-rn"
   },
   "source": [
    "Develop an advanced support ticket categorization system that accurately classifies incoming tickets, assigns relevant tags based on their content, implements mechanisms and generate the first response based on the sentiment for prioritizing tickets for prompt resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bonUQGu23RK"
   },
   "source": [
    "## **Installing and Importing Necessary Libraries and Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bSZp9UgqNVS4"
   },
   "outputs": [],
   "source": [
    "# for loading and manipulating data.\n",
    "# try:\n",
    "#   import pandas as pd\n",
    "# except:\n",
    "#   pip uninstall numpy\n",
    "#   pip install numpy==1.15.1\n",
    "#   import pandas as pd\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "# # for time computations.\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0rHx0ZC5Jbv",
    "outputId": "8719d476-0c08-40ed-ee54-040293b62675"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'CMAKE_ARGS' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Installation for GPU llama-cpp-python.\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lrU246OBS0MP"
   },
   "outputs": [],
   "source": [
    "# Importing the Llama class from the llama_cpp module.\n",
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "awsKQRs-OYo8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-expr 1.1.13 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# For downloading the models from HF Hub.\n",
    "# !pip install huggingface_hub==0.20.3 pandas==1.5.3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0x29JGHMqD74"
   },
   "outputs": [],
   "source": [
    "# Function to download the model from the Hugging Face model hub.\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Importing the json module.\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTpWESc53dL9"
   },
   "source": [
    "## **Loading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ksv9hSCR4BM_"
   },
   "outputs": [],
   "source": [
    "# Loading the data into df\n",
    "df = pd.read_csv(\"Support_ticket_text_data_mid_term.csv\")\n",
    "\n",
    "# Creating copy of 'df' in the variable data\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8qUEOcQ3j5q"
   },
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3YXcM8G3ljS"
   },
   "source": [
    "### Checking the first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bNOTBqaNVG4j",
    "outputId": "784148c6-f8d9-4952-f304-fdc2ffa02b31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  support_tick_id                                support_ticket_text\n",
       "0      ST2023-006  My internet connection has significantly slowe...\n",
       "1      ST2023-007  Urgent help required! My laptop refuses to sta...\n",
       "2      ST2023-008  I've accidentally deleted essential work docum...\n",
       "3      ST2023-009  Despite being in close proximity to my Wi-Fi r...\n",
       "4      ST2023-010  My smartphone battery is draining rapidly, eve..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows of the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UO3pFis3rDj"
   },
   "source": [
    "### Checking the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fLXRyDA4m3S",
    "outputId": "3fd53474-1810-4e37-f7b5-4deb76517c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4g6kMnPxlePH"
   },
   "outputs": [],
   "source": [
    "# There are 21 rows and 2 columns present in this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i1EB_O-3tJp"
   },
   "source": [
    "### Checking the missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rtx1knap5wRt",
    "outputId": "575a3428-73f9-4765-e18b-610803f77b80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values in data\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0mPMqAiCliP1"
   },
   "outputs": [],
   "source": [
    "# From the above output we identify there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qP5KTLo3OOC"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWvf3R3An5K4"
   },
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rF2F_YO_qGtV"
   },
   "outputs": [],
   "source": [
    "# model name and model base name\n",
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "95b7bcbdc30244049555c2b415ba1ea9",
      "831283f977ef4f159a1210f2f48b02f7",
      "8f0551fc12b544ddb62ca4a4c0112caf",
      "ec226f1976e44fba83663baa01c9b03a",
      "47720fca238f4068901cb2c9d0b5d886",
      "f5e31abeba5a4b0a812d80d063d7313f",
      "4ba79b450f12494a901b3c42e3b46609",
      "a55f6b647d874c799e9ef7dcd4ade305",
      "d159ee51bca14573bad77dea32b885f7",
      "756fd6ded4f24c83800c007c5c05745e",
      "d3c2fa17a93e42a3b6440e38c3630c35"
     ]
    },
    "id": "Uk2q7vrc_TrO",
    "outputId": "ff2bfbeb-55a4-46e2-c8d6-f8d04c451a1a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3669850f4bfa4b0fb99d3298405ae8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mistral-7b-instruct-v0.2.Q6_K.gguf:   0%|          | 0.00/5.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Declaring repo_id and filename\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=model_name_or_path, # repo_id = model_name_or_path\n",
    "    filename=model_basename # filename = model_basename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wI_T-0DWXRtD",
    "outputId": "7b12343d-a388-4697-cdf5-129aadc08a45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# Defining the llm model - Llama (Run using GPU)\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=1024, # Context window\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8FxB-MBen3w"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PibZOe6aegGe"
   },
   "outputs": [],
   "source": [
    "# defining a function to parse the JSON output from the model\n",
    "def extract_json_data(json_str):\n",
    "    try:\n",
    "        # Find the indices of the opening and closing curly braces\n",
    "        json_start = json_str.find('{')\n",
    "        json_end = json_str.rfind('}')\n",
    "\n",
    "        if json_start != -1 and json_end != -1:\n",
    "            extracted_category = json_str[json_start:json_end + 1]  # Extract the JSON object\n",
    "            data_dict = json.loads(extracted_category)\n",
    "            return data_dict\n",
    "        else:\n",
    "            print(f\"Warning: JSON object not found in response: {json_str}\")\n",
    "            return {}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le80Djip27mc"
   },
   "source": [
    "## **Task 1: Ticket Categorization and Returning Structured Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2opKxTRX3Ksw"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vzdh6COH_615"
   },
   "outputs": [],
   "source": [
    "# Defining the response funciton for Task 1.\n",
    "def response_1(prompt,ticket):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=10, # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01, # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "o4fvrtrB3P_G"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 1\n",
    "prompt_1 = \"\"\"\n",
    "   As an AI, your job is to categorize IT support tickets. \n",
    "   Please label each ticket as either a Hardware Issue, Data Recovery, or Technical Issue. \n",
    "   Your response should be in the format: {\"category\": \"Hardware Issues\"}, {\"category\": \"Data Recovery\"}, or {\"category\": \"Technical Issues\"}. \n",
    "   Keep your output simple and accurate. Ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afxdh6opkyfj"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UinALS1l3XjW",
    "outputId": "6b2f293c-5517-44d4-fa51-eab3211bea29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text \n",
    "start = time.time()\n",
    "data_1['model_response'] = data_1['support_ticket_text'].apply(lambda x: response_1(prompt_1, x))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bo0YlHPXAJfP",
    "outputId": "984dd8d6-7ea9-4465-8420-d2dc38329428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 280 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time taken for model to return output\n",
    "print(\"Time taken:\", round((end-start)),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "pHn-R-fx31Uq",
    "outputId": "9a3e048a-f8a7-4128-f868-5efe0638b396"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {\"category\": \"Technical Issues\"}\n",
       "1     {\"category\": \"Hardware Issues\"}\n",
       "2       {\"category\": \"Data Recovery\"}\n",
       "3    {\"category\": \"Technical Issues\"}\n",
       "4     {\"category\": \"Hardware Issues\"}\n",
       "Name: model_response, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial model output\n",
    "data_1['model_response'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbHTOL494CkV",
    "outputId": "be4f2e67-376d-433c-dabf-0ef97f1d877c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My computer's performance is sluggish, severely impacting my work. I need help optimizing it to regain productivity.\n"
     ]
    }
   ],
   "source": [
    "# Displaying the support ticket text\n",
    "i = 6\n",
    "print(data_1.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB9h31T54H4F",
    "outputId": "736c9af9-d6ea-4815-b6c0-5248246cf93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"category\": \"Technical Issues\"}\n"
     ]
    }
   ],
   "source": [
    "# Model output\n",
    "print(data_1.loc[i, 'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "PLjf4Kgu41oJ",
    "outputId": "9e433b3d-d28b-4f2f-8ba9-139ac66ca161"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'category': 'Technical Issues'}\n",
       "1     {'category': 'Hardware Issues'}\n",
       "2       {'category': 'Data Recovery'}\n",
       "3    {'category': 'Technical Issues'}\n",
       "4     {'category': 'Hardware Issues'}\n",
       "Name: model_response_parsed, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the function to the model response\n",
    "data_1['model_response_parsed'] = data_1['model_response'].apply(extract_json_data)\n",
    "data_1['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "OXi7nOzyeGdK",
    "outputId": "af18fa55-045c-40a8-8728-e73115091779"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'Technical Issues'}    7\n",
       "{'category': 'Hardware Issues'}     7\n",
       "{'category': 'Data Recovery'}       7\n",
       "Name: model_response_parsed, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output after extracting JSON data\n",
    "data_1['model_response_parsed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pnivjGUcUONC",
    "outputId": "31da8a60-7af0-4d0d-f2bd-9ef154bcdee1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hardware Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technical Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hardware Issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category\n",
       "0  Technical Issues\n",
       "1   Hardware Issues\n",
       "2     Data Recovery\n",
       "3  Technical Issues\n",
       "4   Hardware Issues"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_1 = pd.json_normalize(data_1['model_response_parsed'])\n",
    "model_response_parsed_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "V67nKkfUUd1c",
    "outputId": "df9395c3-07ff-4727-f8f9-b4b5d33678bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>model_response</th>\n",
       "      <th>model_response_parsed</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>{\"category\": \"Technical Issues\"}</td>\n",
       "      <td>{'category': 'Technical Issues'}</td>\n",
       "      <td>Technical Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>{\"category\": \"Hardware Issues\"}</td>\n",
       "      <td>{'category': 'Hardware Issues'}</td>\n",
       "      <td>Hardware Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>{\"category\": \"Data Recovery\"}</td>\n",
       "      <td>{'category': 'Data Recovery'}</td>\n",
       "      <td>Data Recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>{\"category\": \"Technical Issues\"}</td>\n",
       "      <td>{'category': 'Technical Issues'}</td>\n",
       "      <td>Technical Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>{\"category\": \"Hardware Issues\"}</td>\n",
       "      <td>{'category': 'Hardware Issues'}</td>\n",
       "      <td>Hardware Issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  support_tick_id                                support_ticket_text  \\\n",
       "0      ST2023-006  My internet connection has significantly slowe...   \n",
       "1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n",
       "2      ST2023-008  I've accidentally deleted essential work docum...   \n",
       "3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n",
       "4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n",
       "\n",
       "                     model_response             model_response_parsed  \\\n",
       "0  {\"category\": \"Technical Issues\"}  {'category': 'Technical Issues'}   \n",
       "1   {\"category\": \"Hardware Issues\"}   {'category': 'Hardware Issues'}   \n",
       "2     {\"category\": \"Data Recovery\"}     {'category': 'Data Recovery'}   \n",
       "3  {\"category\": \"Technical Issues\"}  {'category': 'Technical Issues'}   \n",
       "4   {\"category\": \"Hardware Issues\"}   {'category': 'Hardware Issues'}   \n",
       "\n",
       "           category  \n",
       "0  Technical Issues  \n",
       "1   Hardware Issues  \n",
       "2     Data Recovery  \n",
       "3  Technical Issues  \n",
       "4   Hardware Issues  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_1 = pd.concat([data_1, model_response_parsed_df_1], axis=1)\n",
    "data_with_parsed_model_output_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dHxzez70U0Dv",
    "outputId": "7d2f6a50-6c02-492e-efa4-aa443ed9dd36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>Technical Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>Data Recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>Technical Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  support_tick_id                                support_ticket_text  \\\n",
       "0      ST2023-006  My internet connection has significantly slowe...   \n",
       "1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n",
       "2      ST2023-008  I've accidentally deleted essential work docum...   \n",
       "3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n",
       "4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n",
       "\n",
       "           category  \n",
       "0  Technical Issues  \n",
       "1   Hardware Issues  \n",
       "2     Data Recovery  \n",
       "3  Technical Issues  \n",
       "4   Hardware Issues  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_1 = data_with_parsed_model_output_1.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z795llV0elBQ"
   },
   "source": [
    "## **Task 2: Creating Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wWlFOeCFf5Zx"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WSflU6-CBk29"
   },
   "outputs": [],
   "source": [
    "def response_2(prompt,ticket,category):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      Category: {category}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=1024,  # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01,  # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kODQ_X5Vf7gJ"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 2\n",
    "prompt_2 = \"\"\"\n",
    "   As an AI, your task is to label IT support tickets with relevant tags. \n",
    "   Please identify the most appropriate keywords and include them in your response. \n",
    "   Your output should be formatted as follows: {\"tags\": [\"Wifi\", \"Data Loss\", \"Connection Issues\", \"Battery\"]}.\n",
    "   Keep your output simple and accurate. Ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlnUmTSKlD-O"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEQu4_lUgcdW",
    "outputId": "23d44985-4d9b-4fda-e187-682cc39a55b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text\n",
    "start = time.time()\n",
    "data_2[\"model_response\"]=final_data_1[['support_ticket_text','category']].apply(lambda x: response_2(prompt_2, x[0],x[1]),axis =1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_GeduRusM1i3",
    "outputId": "3279ab2e-ce4b-4fbb-b15a-4a6588334b4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2349  seconds\n"
     ]
    }
   ],
   "source": [
    "# Time taken for model to generate output\n",
    "print(\"Time taken:\",round((end-start)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "y023-XNxgpYd",
    "outputId": "55186f07-4f48-47b1-cae9-d59aacea7539"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {\"tags\": [\"Connection Issues\", \"Internet\", \"Sl...\n",
       "1             {\"tags\": [\"Hardware\", \"Startup Issues\"]}\n",
       "2                              {\"tags\": [\"Data Loss\"]}\n",
       "3              {\"tags\": [\"Wifi\", \"Connection Issues\"]}\n",
       "4                                {\"tags\": [\"Battery\"]}\n",
       "Name: model_response, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial model output\n",
    "data_2['model_response'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqOM7mntgsJ6",
    "outputId": "2eeffa7e-9160-41d4-91c3-d032e65e99c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My internet connection has significantly slowed down over the past two days, making it challenging to work efficiently from home. Frequent disconnections are causing major disruptions. Please assist in resolving this connectivity issue promptly.\n"
     ]
    }
   ],
   "source": [
    "# Support ticket text\n",
    "i = 0\n",
    "print(data_2.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IayJkEP1gr96",
    "outputId": "d38724c8-9f39-48d5-ca25-ce4b790e8a90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"tags\": [\"Connection Issues\", \"Internet\", \"Slow Connection\"]}\n"
     ]
    }
   ],
   "source": [
    "# Model output\n",
    "print(data_2.loc[i,'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "D8CTPgPQhKcx"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_2['model_response_parsed'] = data_2['model_response'].apply(extract_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "3om_9wk4W8_l",
    "outputId": "1ae16d04-2eec-47a0-9800-c3177441a8df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'tags': ['Connection Issues', 'Internet', 'Sl...\n",
       "1              {'tags': ['Hardware', 'Startup Issues']}\n",
       "2                               {'tags': ['Data Loss']}\n",
       "3               {'tags': ['Wifi', 'Connection Issues']}\n",
       "4                                 {'tags': ['Battery']}\n",
       "5             {'tags': ['Data Loss', 'Account Access']}\n",
       "6             {'tags': ['Performance', 'Productivity']}\n",
       "7           {'tags': ['Hardware', 'Blue Screen Error']}\n",
       "8                               {'tags': ['Data Loss']}\n",
       "9     {'tags': ['Graphics Card', 'Hardware', 'Perfor...\n",
       "10                              {'tags': ['Data Loss']}\n",
       "11                     {'tags': ['Screen', 'Hardware']}\n",
       "12           {'tags': ['Hardware', 'Laptop', 'Damage']}\n",
       "13                              {'tags': ['Data Loss']}\n",
       "14                               {'tags': ['Hardware']}\n",
       "15          {'tags': ['Connection Issues', 'Internet']}\n",
       "16              {'tags': ['Wifi', 'Connection Issues']}\n",
       "17                              {'tags': ['Data Loss']}\n",
       "18                              {'tags': ['Data Loss']}\n",
       "19    {'tags': ['Connection Issues', 'Internet', 'Sl...\n",
       "20           {'tags': ['Software Issues', 'Data Loss']}\n",
       "Name: model_response_parsed, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output after extracting JSON data\n",
    "data_2[\"model_response_parsed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6PAke663hN3T",
    "outputId": "0453f9db-9b70-4ae7-f5df-e010eb490545"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Connection Issues, Internet, Slow Connection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hardware, Startup Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Wifi, Connection Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Battery]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tags\n",
       "0  [Connection Issues, Internet, Slow Connection]\n",
       "1                      [Hardware, Startup Issues]\n",
       "2                                     [Data Loss]\n",
       "3                       [Wifi, Connection Issues]\n",
       "4                                       [Battery]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_2 = pd.json_normalize(data_2['model_response_parsed'])\n",
    "model_response_parsed_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "aXJqZgh-hP4G",
    "outputId": "5edba8bb-6e2f-41cd-a359-eb22a4c620bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>model_response</th>\n",
       "      <th>model_response_parsed</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>{\"tags\": [\"Connection Issues\", \"Internet\", \"Sl...</td>\n",
       "      <td>{'tags': ['Connection Issues', 'Internet', 'Sl...</td>\n",
       "      <td>[Connection Issues, Internet, Slow Connection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>{\"tags\": [\"Hardware\", \"Startup Issues\"]}</td>\n",
       "      <td>{'tags': ['Hardware', 'Startup Issues']}</td>\n",
       "      <td>[Hardware, Startup Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>{\"tags\": [\"Data Loss\"]}</td>\n",
       "      <td>{'tags': ['Data Loss']}</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>{\"tags\": [\"Wifi\", \"Connection Issues\"]}</td>\n",
       "      <td>{'tags': ['Wifi', 'Connection Issues']}</td>\n",
       "      <td>[Wifi, Connection Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>{\"tags\": [\"Battery\"]}</td>\n",
       "      <td>{'tags': ['Battery']}</td>\n",
       "      <td>[Battery]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  support_tick_id                                support_ticket_text  \\\n",
       "0      ST2023-006  My internet connection has significantly slowe...   \n",
       "1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n",
       "2      ST2023-008  I've accidentally deleted essential work docum...   \n",
       "3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n",
       "4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n",
       "\n",
       "                                      model_response  \\\n",
       "0  {\"tags\": [\"Connection Issues\", \"Internet\", \"Sl...   \n",
       "1           {\"tags\": [\"Hardware\", \"Startup Issues\"]}   \n",
       "2                            {\"tags\": [\"Data Loss\"]}   \n",
       "3            {\"tags\": [\"Wifi\", \"Connection Issues\"]}   \n",
       "4                              {\"tags\": [\"Battery\"]}   \n",
       "\n",
       "                               model_response_parsed  \\\n",
       "0  {'tags': ['Connection Issues', 'Internet', 'Sl...   \n",
       "1           {'tags': ['Hardware', 'Startup Issues']}   \n",
       "2                            {'tags': ['Data Loss']}   \n",
       "3            {'tags': ['Wifi', 'Connection Issues']}   \n",
       "4                              {'tags': ['Battery']}   \n",
       "\n",
       "                                             tags  \n",
       "0  [Connection Issues, Internet, Slow Connection]  \n",
       "1                      [Hardware, Startup Issues]  \n",
       "2                                     [Data Loss]  \n",
       "3                       [Wifi, Connection Issues]  \n",
       "4                                       [Battery]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_2 = pd.concat([data_2, model_response_parsed_df_2], axis=1)\n",
    "data_with_parsed_model_output_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vsT9xR1FhSRZ",
    "outputId": "b76c8454-befa-42e4-9b4f-b0636b9944b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>[Connection Issues, Internet, Slow Connection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>[Hardware, Startup Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>[Wifi, Connection Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>[Battery]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  support_tick_id                                support_ticket_text  \\\n",
       "0      ST2023-006  My internet connection has significantly slowe...   \n",
       "1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n",
       "2      ST2023-008  I've accidentally deleted essential work docum...   \n",
       "3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n",
       "4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n",
       "\n",
       "                                             tags  \n",
       "0  [Connection Issues, Internet, Slow Connection]  \n",
       "1                      [Hardware, Startup Issues]  \n",
       "2                                     [Data Loss]  \n",
       "3                       [Wifi, Connection Issues]  \n",
       "4                                       [Battery]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_2 = data_with_parsed_model_output_2.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "4UAvaviZhUW4",
    "outputId": "1efe4dbf-2d70-4aad-9286-80e5acf1e0e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data Loss]                                       6\n",
       "[Wifi, Connection Issues]                         2\n",
       "[Connection Issues, Internet, Slow Connection]    1\n",
       "[Hardware, Startup Issues]                        1\n",
       "[Battery]                                         1\n",
       "[Data Loss, Account Access]                       1\n",
       "[Performance, Productivity]                       1\n",
       "[Hardware, Blue Screen Error]                     1\n",
       "[Graphics Card, Hardware, Performance]            1\n",
       "[Screen, Hardware]                                1\n",
       "[Hardware, Laptop, Damage]                        1\n",
       "[Hardware]                                        1\n",
       "[Connection Issues, Internet]                     1\n",
       "[Connection Issues, Internet, Slow Speed]         1\n",
       "[Software Issues, Data Loss]                      1\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the value counts of Category column\n",
    "final_data_2['tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4NybVxPKS8k3"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "final_data_2 = pd.concat([final_data_2,final_data_1[\"category\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Kt24BSz6THBr",
    "outputId": "0718e606-5dd4-4ea1-c819-6bf722cbe2f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Connection Issues, Internet, Slow Connection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware, Startup Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Wifi, Connection Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Battery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ST2023-011</td>\n",
       "      <td>I'm locked out of my online banking account an...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss, Account Access]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ST2023-012</td>\n",
       "      <td>My computer's performance is sluggish, severel...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Performance, Productivity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ST2023-013</td>\n",
       "      <td>I'm experiencing a recurring blue screen error...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware, Blue Screen Error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST2023-014</td>\n",
       "      <td>My external hard drive isn't being recognized ...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ST2023-015</td>\n",
       "      <td>The graphics card in my gaming laptop seems to...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Graphics Card, Hardware, Performance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ST2023-016</td>\n",
       "      <td>I accidentally formatted my USB drive with cri...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ST2023-017</td>\n",
       "      <td>My computer's screen has gone black, and I can...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Screen, Hardware]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ST2023-018</td>\n",
       "      <td>I accidentally spilled water on my laptop, and...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware, Laptop, Damage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ST2023-019</td>\n",
       "      <td>My USB flash drive is physically damaged, and ...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ST2023-020</td>\n",
       "      <td>The touchpad on my laptop has stopped working,...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ST2023-021</td>\n",
       "      <td>My internet connection is frequently dropping,...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Connection Issues, Internet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ST2023-022</td>\n",
       "      <td>Wi-Fi is inconsistent despite proximity to the...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Wifi, Connection Issues]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ST2023-023</td>\n",
       "      <td>I accidentally formatted my USB drive with cru...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ST2023-024</td>\n",
       "      <td>My external hard drive isn't being recognized,...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ST2023-025</td>\n",
       "      <td>I am experiencing a critical problem with my i...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Connection Issues, Internet, Slow Speed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ST2023-026</td>\n",
       "      <td>I hope this message finds you well. I am writi...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Software Issues, Data Loss]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support_tick_id                                support_ticket_text  \\\n",
       "0       ST2023-006  My internet connection has significantly slowe...   \n",
       "1       ST2023-007  Urgent help required! My laptop refuses to sta...   \n",
       "2       ST2023-008  I've accidentally deleted essential work docum...   \n",
       "3       ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n",
       "4       ST2023-010  My smartphone battery is draining rapidly, eve...   \n",
       "5       ST2023-011  I'm locked out of my online banking account an...   \n",
       "6       ST2023-012  My computer's performance is sluggish, severel...   \n",
       "7       ST2023-013  I'm experiencing a recurring blue screen error...   \n",
       "8       ST2023-014  My external hard drive isn't being recognized ...   \n",
       "9       ST2023-015  The graphics card in my gaming laptop seems to...   \n",
       "10      ST2023-016  I accidentally formatted my USB drive with cri...   \n",
       "11      ST2023-017  My computer's screen has gone black, and I can...   \n",
       "12      ST2023-018  I accidentally spilled water on my laptop, and...   \n",
       "13      ST2023-019  My USB flash drive is physically damaged, and ...   \n",
       "14      ST2023-020  The touchpad on my laptop has stopped working,...   \n",
       "15      ST2023-021  My internet connection is frequently dropping,...   \n",
       "16      ST2023-022  Wi-Fi is inconsistent despite proximity to the...   \n",
       "17      ST2023-023  I accidentally formatted my USB drive with cru...   \n",
       "18      ST2023-024  My external hard drive isn't being recognized,...   \n",
       "19      ST2023-025  I am experiencing a critical problem with my i...   \n",
       "20      ST2023-026  I hope this message finds you well. I am writi...   \n",
       "\n",
       "            category                                            tags  \n",
       "0   Technical Issues  [Connection Issues, Internet, Slow Connection]  \n",
       "1    Hardware Issues                      [Hardware, Startup Issues]  \n",
       "2      Data Recovery                                     [Data Loss]  \n",
       "3   Technical Issues                       [Wifi, Connection Issues]  \n",
       "4    Hardware Issues                                       [Battery]  \n",
       "5      Data Recovery                     [Data Loss, Account Access]  \n",
       "6   Technical Issues                     [Performance, Productivity]  \n",
       "7    Hardware Issues                   [Hardware, Blue Screen Error]  \n",
       "8      Data Recovery                                     [Data Loss]  \n",
       "9    Hardware Issues          [Graphics Card, Hardware, Performance]  \n",
       "10     Data Recovery                                     [Data Loss]  \n",
       "11   Hardware Issues                              [Screen, Hardware]  \n",
       "12   Hardware Issues                      [Hardware, Laptop, Damage]  \n",
       "13     Data Recovery                                     [Data Loss]  \n",
       "14   Hardware Issues                                      [Hardware]  \n",
       "15  Technical Issues                   [Connection Issues, Internet]  \n",
       "16  Technical Issues                       [Wifi, Connection Issues]  \n",
       "17     Data Recovery                                     [Data Loss]  \n",
       "18     Data Recovery                                     [Data Loss]  \n",
       "19  Technical Issues       [Connection Issues, Internet, Slow Speed]  \n",
       "20  Technical Issues                    [Software Issues, Data Loss]  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing newly updated dataframe\n",
    "final_data_2 = final_data_2[[\"support_tick_id\",\"support_ticket_text\",\"category\",\"tags\"]]\n",
    "final_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdwE7rguh8sD"
   },
   "source": [
    "## **Task 3: Assigning Priority and ETA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "4FS158JYiUXY"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_3 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "sHjSvP9maGFt"
   },
   "outputs": [],
   "source": [
    "# Function created to generate an output from the model\n",
    "def response_3(prompt,ticket,category,tags):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      Category: {category}\n",
    "      Tags: {tags}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=20,   # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01,  # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "    final_output = temp_output[temp_output.index('{'):]\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "rUHUh2mRiUUK"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 3\n",
    "prompt_3 = \"\"\"\n",
    "    As an AI, your task is to determine the priority and estimated time to resolve (ETA) for IT support tickets. \n",
    "    Consider the severity of the issue, the time needed for resolution, and customer satisfaction. \n",
    "    Your response should be in the format: {\"priority\": \"High\", \"eta\": \"2 Days\"}.\n",
    "    Keep your output simple and accurate. Ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VZ1BUwslKHD"
   },
   "source": [
    "**Note**: The output of the model should be in a structured format (JSON format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC2Ygg4AiUR6",
    "outputId": "291e07a9-73fe-47e4-cad0-05986f000652"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text  \n",
    "start = time.time()\n",
    "data_3['model_response'] = final_data_2[['support_ticket_text','category','tags']].apply(lambda x: response_3(prompt_3, x[0],x[1],x[2]),axis=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXnus6Akhmr8",
    "outputId": "d6b7cb3c-9f36-47a1-b4d0-a047074ab6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 403  seconds\n"
     ]
    }
   ],
   "source": [
    "# Time taken for model to generate output\n",
    "print(\"Time taken:\",round((end-start)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "LsvGelDZiUPL",
    "outputId": "68974f0b-5470-4d33-e25e-4470297b8647",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {\"priority\": \"High\", \"eta\": \"3 Days\"}\n",
       "1    {\"priority\": \"High\", \"eta\": \"Same Day\"}\n",
       "2      {\"priority\": \"High\", \"eta\": \"3 Days\"}\n",
       "3    {\"priority\": \"Medium\", \"eta\": \"3 Days\"}\n",
       "4    {\"priority\": \"Medium\", \"eta\": \"3 Days\"}\n",
       "Name: model_response, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial model output\n",
    "data_3['model_response'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_iOXhT1iUMd",
    "outputId": "e1c51f79-c6fe-4566-c02d-9652c86717e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite being in close proximity to my Wi-Fi router, the signal remains persistently weak in my home. This issue has been ongoing, and I need assistance troubleshooting it. Please help me resolve the weak Wi-Fi signal problem.\n"
     ]
    }
   ],
   "source": [
    "# Support ticket text\n",
    "i = 3\n",
    "print(data_3.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlqV49CeiUJz",
    "outputId": "463d1b6a-536b-41c2-80a5-21975a1aadf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"priority\": \"Medium\", \"eta\": \"3 Days\"}\n"
     ]
    }
   ],
   "source": [
    "# Model output\n",
    "print(data_3.loc[i,'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "h1F87rEpm70v",
    "outputId": "ccb9f6cc-a68d-4e96-8d0d-88b1f2ed01df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'priority': 'High', 'eta': '3 Days'}\n",
       "1    {'priority': 'High', 'eta': 'Same Day'}\n",
       "2      {'priority': 'High', 'eta': '3 Days'}\n",
       "3    {'priority': 'Medium', 'eta': '3 Days'}\n",
       "4    {'priority': 'Medium', 'eta': '3 Days'}\n",
       "Name: model_response_parsed, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the function to the model response\n",
    "data_3['model_response_parsed'] = data_3['model_response'].apply(extract_json_data)\n",
    "data_3['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "BGLu4BJEnDQq",
    "outputId": "23279659-3287-492a-879c-dbb22386651b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priority</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>High</td>\n",
       "      <td>Same Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   priority       eta\n",
       "0      High    3 Days\n",
       "1      High  Same Day\n",
       "2      High    3 Days\n",
       "3    Medium    3 Days\n",
       "4    Medium    3 Days\n",
       "5      High     1 Day\n",
       "6      High    3 Days\n",
       "7      High    3 Days\n",
       "8      High    3 Days\n",
       "9      High    3 Days\n",
       "10     High    3 Days\n",
       "11     High    3 Days\n",
       "12     High    3 Days\n",
       "13     High    3 Days\n",
       "14     High    3 Days\n",
       "15     High     1 Day\n",
       "16     High     1 Day\n",
       "17     High    3 Days\n",
       "18     High    3 Days\n",
       "19     High     1 Day\n",
       "20     High    3 Days"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_3 = pd.json_normalize(data_3['model_response_parsed'])\n",
    "model_response_parsed_df_3.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "4x7VEKDcnL11",
    "outputId": "a4bcbe82-0a98-4dcb-a23e-bc00a5c243b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>model_response</th>\n",
       "      <th>model_response_parsed</th>\n",
       "      <th>priority</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>{\"priority\": \"High\", \"eta\": \"3 Days\"}</td>\n",
       "      <td>{'priority': 'High', 'eta': '3 Days'}</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>{\"priority\": \"High\", \"eta\": \"Same Day\"}</td>\n",
       "      <td>{'priority': 'High', 'eta': 'Same Day'}</td>\n",
       "      <td>High</td>\n",
       "      <td>Same Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>{\"priority\": \"High\", \"eta\": \"3 Days\"}</td>\n",
       "      <td>{'priority': 'High', 'eta': '3 Days'}</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>{\"priority\": \"Medium\", \"eta\": \"3 Days\"}</td>\n",
       "      <td>{'priority': 'Medium', 'eta': '3 Days'}</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>{\"priority\": \"Medium\", \"eta\": \"3 Days\"}</td>\n",
       "      <td>{'priority': 'Medium', 'eta': '3 Days'}</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  support_tick_id                                support_ticket_text  \\\n",
       "0      ST2023-006  My internet connection has significantly slowe...   \n",
       "1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n",
       "2      ST2023-008  I've accidentally deleted essential work docum...   \n",
       "3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n",
       "4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n",
       "\n",
       "                            model_response  \\\n",
       "0    {\"priority\": \"High\", \"eta\": \"3 Days\"}   \n",
       "1  {\"priority\": \"High\", \"eta\": \"Same Day\"}   \n",
       "2    {\"priority\": \"High\", \"eta\": \"3 Days\"}   \n",
       "3  {\"priority\": \"Medium\", \"eta\": \"3 Days\"}   \n",
       "4  {\"priority\": \"Medium\", \"eta\": \"3 Days\"}   \n",
       "\n",
       "                     model_response_parsed priority       eta  \n",
       "0    {'priority': 'High', 'eta': '3 Days'}     High    3 Days  \n",
       "1  {'priority': 'High', 'eta': 'Same Day'}     High  Same Day  \n",
       "2    {'priority': 'High', 'eta': '3 Days'}     High    3 Days  \n",
       "3  {'priority': 'Medium', 'eta': '3 Days'}   Medium    3 Days  \n",
       "4  {'priority': 'Medium', 'eta': '3 Days'}   Medium    3 Days  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatinating two dataframes\n",
    "data_with_parsed_model_output_3 = pd.concat([data_3, model_response_parsed_df_3], axis=1)\n",
    "data_with_parsed_model_output_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gz8WprxNnONN",
    "outputId": "7b187caf-df51-4d7f-8fec-e72f1d07f939"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>priority</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>High</td>\n",
       "      <td>Same Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  support_tick_id                                support_ticket_text priority  \\\n",
       "0      ST2023-006  My internet connection has significantly slowe...     High   \n",
       "1      ST2023-007  Urgent help required! My laptop refuses to sta...     High   \n",
       "2      ST2023-008  I've accidentally deleted essential work docum...     High   \n",
       "3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   Medium   \n",
       "4      ST2023-010  My smartphone battery is draining rapidly, eve...   Medium   \n",
       "\n",
       "        eta  \n",
       "0    3 Days  \n",
       "1  Same Day  \n",
       "2    3 Days  \n",
       "3    3 Days  \n",
       "4    3 Days  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping model_response and model_response_parsed columns\n",
    "final_data_3 = data_with_parsed_model_output_3.drop(['model_response','model_response_parsed'], axis=1)\n",
    "final_data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "x3Kmwtwvj_NO"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "final_data_3 = pd.concat([final_data_3,final_data_2[[\"category\",\"tags\"]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "mVa9DmktkL-x"
   },
   "outputs": [],
   "source": [
    "# Creating new dataframe\n",
    "final_data_3 = final_data_3[[\"support_tick_id\",\"support_ticket_text\",\"category\",\"tags\",\"priority\",\"eta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "da_W2ybekZHD",
    "outputId": "28ac0f7f-bf10-4b23-d56b-7556548e17a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support_tick_id</th>\n",
       "      <th>support_ticket_text</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>priority</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ST2023-006</td>\n",
       "      <td>My internet connection has significantly slowe...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Connection Issues, Internet, Slow Connection]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ST2023-007</td>\n",
       "      <td>Urgent help required! My laptop refuses to sta...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware, Startup Issues]</td>\n",
       "      <td>High</td>\n",
       "      <td>Same Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST2023-008</td>\n",
       "      <td>I've accidentally deleted essential work docum...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ST2023-009</td>\n",
       "      <td>Despite being in close proximity to my Wi-Fi r...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Wifi, Connection Issues]</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ST2023-010</td>\n",
       "      <td>My smartphone battery is draining rapidly, eve...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Battery]</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ST2023-011</td>\n",
       "      <td>I'm locked out of my online banking account an...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss, Account Access]</td>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ST2023-012</td>\n",
       "      <td>My computer's performance is sluggish, severel...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Performance, Productivity]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ST2023-013</td>\n",
       "      <td>I'm experiencing a recurring blue screen error...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware, Blue Screen Error]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ST2023-014</td>\n",
       "      <td>My external hard drive isn't being recognized ...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ST2023-015</td>\n",
       "      <td>The graphics card in my gaming laptop seems to...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Graphics Card, Hardware, Performance]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ST2023-016</td>\n",
       "      <td>I accidentally formatted my USB drive with cri...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ST2023-017</td>\n",
       "      <td>My computer's screen has gone black, and I can...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Screen, Hardware]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ST2023-018</td>\n",
       "      <td>I accidentally spilled water on my laptop, and...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware, Laptop, Damage]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ST2023-019</td>\n",
       "      <td>My USB flash drive is physically damaged, and ...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ST2023-020</td>\n",
       "      <td>The touchpad on my laptop has stopped working,...</td>\n",
       "      <td>Hardware Issues</td>\n",
       "      <td>[Hardware]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ST2023-021</td>\n",
       "      <td>My internet connection is frequently dropping,...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Connection Issues, Internet]</td>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ST2023-022</td>\n",
       "      <td>Wi-Fi is inconsistent despite proximity to the...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Wifi, Connection Issues]</td>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ST2023-023</td>\n",
       "      <td>I accidentally formatted my USB drive with cru...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ST2023-024</td>\n",
       "      <td>My external hard drive isn't being recognized,...</td>\n",
       "      <td>Data Recovery</td>\n",
       "      <td>[Data Loss]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ST2023-025</td>\n",
       "      <td>I am experiencing a critical problem with my i...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Connection Issues, Internet, Slow Speed]</td>\n",
       "      <td>High</td>\n",
       "      <td>1 Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ST2023-026</td>\n",
       "      <td>I hope this message finds you well. I am writi...</td>\n",
       "      <td>Technical Issues</td>\n",
       "      <td>[Software Issues, Data Loss]</td>\n",
       "      <td>High</td>\n",
       "      <td>3 Days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support_tick_id                                support_ticket_text  \\\n",
       "0       ST2023-006  My internet connection has significantly slowe...   \n",
       "1       ST2023-007  Urgent help required! My laptop refuses to sta...   \n",
       "2       ST2023-008  I've accidentally deleted essential work docum...   \n",
       "3       ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n",
       "4       ST2023-010  My smartphone battery is draining rapidly, eve...   \n",
       "5       ST2023-011  I'm locked out of my online banking account an...   \n",
       "6       ST2023-012  My computer's performance is sluggish, severel...   \n",
       "7       ST2023-013  I'm experiencing a recurring blue screen error...   \n",
       "8       ST2023-014  My external hard drive isn't being recognized ...   \n",
       "9       ST2023-015  The graphics card in my gaming laptop seems to...   \n",
       "10      ST2023-016  I accidentally formatted my USB drive with cri...   \n",
       "11      ST2023-017  My computer's screen has gone black, and I can...   \n",
       "12      ST2023-018  I accidentally spilled water on my laptop, and...   \n",
       "13      ST2023-019  My USB flash drive is physically damaged, and ...   \n",
       "14      ST2023-020  The touchpad on my laptop has stopped working,...   \n",
       "15      ST2023-021  My internet connection is frequently dropping,...   \n",
       "16      ST2023-022  Wi-Fi is inconsistent despite proximity to the...   \n",
       "17      ST2023-023  I accidentally formatted my USB drive with cru...   \n",
       "18      ST2023-024  My external hard drive isn't being recognized,...   \n",
       "19      ST2023-025  I am experiencing a critical problem with my i...   \n",
       "20      ST2023-026  I hope this message finds you well. I am writi...   \n",
       "\n",
       "            category                                            tags priority  \\\n",
       "0   Technical Issues  [Connection Issues, Internet, Slow Connection]     High   \n",
       "1    Hardware Issues                      [Hardware, Startup Issues]     High   \n",
       "2      Data Recovery                                     [Data Loss]     High   \n",
       "3   Technical Issues                       [Wifi, Connection Issues]   Medium   \n",
       "4    Hardware Issues                                       [Battery]   Medium   \n",
       "5      Data Recovery                     [Data Loss, Account Access]     High   \n",
       "6   Technical Issues                     [Performance, Productivity]     High   \n",
       "7    Hardware Issues                   [Hardware, Blue Screen Error]     High   \n",
       "8      Data Recovery                                     [Data Loss]     High   \n",
       "9    Hardware Issues          [Graphics Card, Hardware, Performance]     High   \n",
       "10     Data Recovery                                     [Data Loss]     High   \n",
       "11   Hardware Issues                              [Screen, Hardware]     High   \n",
       "12   Hardware Issues                      [Hardware, Laptop, Damage]     High   \n",
       "13     Data Recovery                                     [Data Loss]     High   \n",
       "14   Hardware Issues                                      [Hardware]     High   \n",
       "15  Technical Issues                   [Connection Issues, Internet]     High   \n",
       "16  Technical Issues                       [Wifi, Connection Issues]     High   \n",
       "17     Data Recovery                                     [Data Loss]     High   \n",
       "18     Data Recovery                                     [Data Loss]     High   \n",
       "19  Technical Issues       [Connection Issues, Internet, Slow Speed]     High   \n",
       "20  Technical Issues                    [Software Issues, Data Loss]     High   \n",
       "\n",
       "         eta  \n",
       "0     3 Days  \n",
       "1   Same Day  \n",
       "2     3 Days  \n",
       "3     3 Days  \n",
       "4     3 Days  \n",
       "5      1 Day  \n",
       "6     3 Days  \n",
       "7     3 Days  \n",
       "8     3 Days  \n",
       "9     3 Days  \n",
       "10    3 Days  \n",
       "11    3 Days  \n",
       "12    3 Days  \n",
       "13    3 Days  \n",
       "14    3 Days  \n",
       "15     1 Day  \n",
       "16     1 Day  \n",
       "17    3 Days  \n",
       "18    3 Days  \n",
       "19     1 Day  \n",
       "20    3 Days  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing newly updated dataframe\n",
    "final_data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7m73qRcne4g"
   },
   "source": [
    "## **Task 4 - Creating a Draft Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "tDe0fY0tnpCS"
   },
   "outputs": [],
   "source": [
    "# creating a copy of the data\n",
    "data_4 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "czJxKYmGlG98"
   },
   "outputs": [],
   "source": [
    "# Function to generate output from the model\n",
    "def response_4(prompt,ticket,category,tags,priority,eta):\n",
    "    model_output = llm(\n",
    "      f\"\"\"\n",
    "      Q: {prompt}\n",
    "      Support ticket: {ticket}\n",
    "      Category : {category}\n",
    "      Tags : {tags}\n",
    "      Priority: {priority}\n",
    "      ETA: {eta}\n",
    "      A:\n",
    "      \"\"\",\n",
    "      max_tokens=1024,  # defining the maximum number of tokens the model should generate for this task.\n",
    "      stop=[\"Q:\", \"\\n\"],\n",
    "      temperature=0.01,  # temperature set to 0.01(low) for deterministic output.\n",
    "      echo=False,\n",
    "    )\n",
    "\n",
    "    temp_output = model_output[\"choices\"][0][\"text\"]\n",
    "\n",
    "    return temp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1CYnMUZUnqkf"
   },
   "outputs": [],
   "source": [
    "# Prompt creation for task 4\n",
    "prompt_4 = \"\"\"\n",
    "    As an AI, your task is to draft a response for IT support tickets. \n",
    "    Consider customer satisfaction, the severity of the issue, and the company's responsibility. \n",
    "    Your response should be in the format: {\"response\": \"This is a draft response\"}. \n",
    "    Ensure your response is empathetic, professional, helpful, and concise.\n",
    "    Please ensure that all curly braces are closed and there are no additional characters in the output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2iYQuTPmcyA"
   },
   "source": [
    "**Note** : For this task, we will not be using the *`extract_json_data`* function. Hence, the output from the model should be a plain string and not a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3UBRIwcnqg8",
    "outputId": "59fa344a-f965-4fc6-c68d-14e5b2eaf302"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Utilizing generate_llama_response as a function on the variable: support_ticket_text \u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 3\u001b[0m data_4[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_response\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_data_3[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport_ticket_text\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: response_4(prompt_4, x[\u001b[38;5;241m0\u001b[39m],x[\u001b[38;5;241m1\u001b[39m],x[\u001b[38;5;241m2\u001b[39m],x[\u001b[38;5;241m3\u001b[39m],x[\u001b[38;5;241m4\u001b[39m]),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Utilizing generate_llama_response as a function on the variable: support_ticket_text \u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 3\u001b[0m data_4[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_response\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_data_3[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport_ticket_text\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: response_4(prompt_4, x[\u001b[38;5;241m0\u001b[39m],x[\u001b[38;5;241m1\u001b[39m],x[\u001b[38;5;241m2\u001b[39m],x[\u001b[38;5;241m3\u001b[39m],x[\u001b[38;5;241m4\u001b[39m]),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[61], line 3\u001b[0m, in \u001b[0;36mresponse_4\u001b[1;34m(prompt, ticket, category, tags, priority, eta)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresponse_4\u001b[39m(prompt,ticket,category,tags,priority,eta):\n\u001b[1;32m----> 3\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m llm(\n\u001b[0;32m      4\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m      Q: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m      Support ticket: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticket\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m      Category : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m      Tags : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtags\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m      Priority: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpriority\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m      ETA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meta\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m      A:\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m       max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,  \u001b[38;5;66;03m# defining the maximum number of tokens the model should generate for this task.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m       stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m       temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,  \u001b[38;5;66;03m# temperature set to 0.01(low) for deterministic output.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m       echo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     19\u001b[0m     temp_output \u001b[38;5;241m=\u001b[39m model_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m temp_output\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_cpp\\llama.py:1441\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[1;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\u001b[0m\n\u001b[0;32m   1395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1397\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     grammar: Optional[LlamaGrammar] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1418\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Completion, Iterator[CompletionChunk]]:\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[0;32m   1420\u001b[0m \n\u001b[0;32m   1421\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;124;03m        Response object containing the generated text.\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_completion(\n\u001b[0;32m   1442\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m   1443\u001b[0m         suffix\u001b[38;5;241m=\u001b[39msuffix,\n\u001b[0;32m   1444\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[0;32m   1445\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m   1446\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   1447\u001b[0m         logprobs\u001b[38;5;241m=\u001b[39mlogprobs,\n\u001b[0;32m   1448\u001b[0m         echo\u001b[38;5;241m=\u001b[39mecho,\n\u001b[0;32m   1449\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   1450\u001b[0m         frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[0;32m   1451\u001b[0m         presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[0;32m   1452\u001b[0m         repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[0;32m   1453\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[0;32m   1454\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1455\u001b[0m         tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[0;32m   1456\u001b[0m         mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[0;32m   1457\u001b[0m         mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[0;32m   1458\u001b[0m         mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[0;32m   1459\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1460\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1461\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m   1462\u001b[0m         grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[0;32m   1463\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_cpp\\llama.py:1392\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[1;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     chunks: Iterator[CompletionChunk] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[1;32m-> 1392\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(completion_or_chunks)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_cpp\\llama.py:945\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[1;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar)\u001b[0m\n\u001b[0;32m    943\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 945\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    946\u001b[0m     prompt_tokens,\n\u001b[0;32m    947\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[0;32m    948\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m    949\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m    950\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[0;32m    951\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[0;32m    952\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[0;32m    953\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[0;32m    954\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[0;32m    955\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[0;32m    956\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[0;32m    957\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m    958\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m    959\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[0;32m    960\u001b[0m ):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_eos:\n\u001b[0;32m    962\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetokenize(completion_tokens)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_cpp\\llama.py:765\u001b[0m, in \u001b[0;36mLlama.generate\u001b[1;34m(self, tokens, top_k, top_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[0;32m    762\u001b[0m     grammar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(tokens)\n\u001b[0;32m    766\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[0;32m    767\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[0;32m    768\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    778\u001b[0m         grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[0;32m    779\u001b[0m     )\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stopping_criteria \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m stopping_criteria(\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_ids\u001b[38;5;241m.\u001b[39mtolist(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scores[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    782\u001b[0m     ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_cpp\\llama.py:484\u001b[0m, in \u001b[0;36mLlama.eval\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    482\u001b[0m n_past \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_ctx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_ids))\n\u001b[0;32m    483\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m--> 484\u001b[0m return_code \u001b[38;5;241m=\u001b[39m llama_cpp\u001b[38;5;241m.\u001b[39mllama_eval(\n\u001b[0;32m    485\u001b[0m     ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx,\n\u001b[0;32m    486\u001b[0m     tokens\u001b[38;5;241m=\u001b[39m(llama_cpp\u001b[38;5;241m.\u001b[39mllama_token \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch))(\u001b[38;5;241m*\u001b[39mbatch),\n\u001b[0;32m    487\u001b[0m     n_tokens\u001b[38;5;241m=\u001b[39mllama_cpp\u001b[38;5;241m.\u001b[39mc_int(n_tokens),\n\u001b[0;32m    488\u001b[0m     n_past\u001b[38;5;241m=\u001b[39mllama_cpp\u001b[38;5;241m.\u001b[39mc_int(n_past),\n\u001b[0;32m    489\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39mllama_cpp\u001b[38;5;241m.\u001b[39mc_int(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_threads),\n\u001b[0;32m    490\u001b[0m )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_eval returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_cpp\\llama_cpp.py:808\u001b[0m, in \u001b[0;36mllama_eval\u001b[1;34m(ctx, tokens, n_tokens, n_past, n_threads)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllama_eval\u001b[39m(\n\u001b[0;32m    802\u001b[0m     ctx: llama_context_p,\n\u001b[0;32m    803\u001b[0m     tokens,  \u001b[38;5;66;03m# type: Array[llama_token]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m     n_threads: c_int,\n\u001b[0;32m    807\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _lib\u001b[38;5;241m.\u001b[39mllama_eval(ctx, tokens, n_tokens, n_past, n_threads)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Utilizing generate_llama_response as a function on the variable: support_ticket_text \n",
    "start = time.time()\n",
    "data_4['model_response'] = final_data_3[['support_ticket_text','category','tags','priority','eta']].apply(lambda x: response_4(prompt_4, x[0],x[1],x[2],x[3],x[4]),axis=1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDtIp9Hmlf9l",
    "outputId": "960cacae-a55a-48f3-e332-9f630cc3cb1a"
   },
   "outputs": [],
   "source": [
    "# Time taken for output to be generated by model\n",
    "print(\"Time taken:\", round((end-start)),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "PyIBbCkcnqeY",
    "outputId": "a556d4c7-2975-441e-c7b1-e020ee198890"
   },
   "outputs": [],
   "source": [
    "# Initial model output\n",
    "data_4['model_response'].head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWkqPHtinqcD",
    "outputId": "1436c95b-f16f-4b38-b184-ca2c23570689"
   },
   "outputs": [],
   "source": [
    "# Support ticket text\n",
    "i = 2\n",
    "print(data_4.loc[i,'support_ticket_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uPa8jt8nqZq",
    "outputId": "49410c75-9ef3-404f-946e-b15a63aade61"
   },
   "outputs": [],
   "source": [
    "# Model output\n",
    "print(data_4.loc[i,'model_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "MQ5FR7Rw2Lg-",
    "outputId": "4a5b44e7-8698-42da-e69e-0d518a06d4e9"
   },
   "outputs": [],
   "source": [
    "# Applying the function to the model response\n",
    "data_4['model_response_parsed'] = data_4['model_response'].apply(extract_json_data)\n",
    "data_4['model_response_parsed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "RtNaRvtt2Lg-",
    "outputId": "45b0fcfa-c5fc-48c2-ea48-98ca9af23877"
   },
   "outputs": [],
   "source": [
    "# Normalizing the model_response_parsed column\n",
    "model_response_parsed_df_4 = pd.json_normalize(data_4['model_response_parsed'])\n",
    "model_response_parsed_df_4.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKlPGXvqpcZ0"
   },
   "outputs": [],
   "source": [
    "# Concatinating two dataframes\n",
    "final_data_4 = pd.concat([final_data_3,model_response_parsed_df_4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-azDlrGegrxL"
   },
   "outputs": [],
   "source": [
    "# Renaming the dataframe\n",
    "final_data_4.rename(columns={\"model_response_parsed\":\"response\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qHgTohqhhLMp",
    "outputId": "96201c75-615c-4f21-8ff1-7f982ea39990"
   },
   "outputs": [],
   "source": [
    "# Viewing newly updated dataframe\n",
    "final_data_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQznlJqM2gSk"
   },
   "source": [
    "## **Model Output Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rb0BE-W20_0K"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe of task 4\n",
    "final_data = final_data_4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "txX3gIQ9WZtD",
    "outputId": "b9b0787f-1768-455b-d76f-863bef15c93a"
   },
   "outputs": [],
   "source": [
    "# Value counts of category\n",
    "final_data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHvAlMpMh7Un"
   },
   "source": [
    "The model output for **category**:\n",
    "> \"Technical Issues\" for 8 tickets\n",
    "\n",
    "> \"Hardware Issues\" for 7 tickets\n",
    "\n",
    "> \"Data Recovery\" for 6 tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "lf-BVS4I2nxJ",
    "outputId": "99182401-e6a7-452a-cd8a-f47ef65a7fda"
   },
   "outputs": [],
   "source": [
    "# Value counts of priority\n",
    "final_data[\"priority\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf6HfjCAiQjN"
   },
   "source": [
    "The model output for **priority** of:\n",
    "\n",
    "> \"High\" to 19 tickets\n",
    "\n",
    "> \"Medium\" to 2 tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "hIkoCfUJ2ntq",
    "outputId": "59495f0b-4953-4c42-bde6-5338a05b3566"
   },
   "outputs": [],
   "source": [
    "# Value counts of ETA\n",
    "final_data[\"eta\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXZR34Z5ieEW"
   },
   "source": [
    "The model output for **ETA** of:\n",
    "> \"3 Days\" to 12 tickets\n",
    "\n",
    "> \"1 Day\" to 9 tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6sgaBLR6t-j"
   },
   "source": [
    "Let's dive in a bit deeper here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "rxtC6q6V6ZSR",
    "outputId": "daa5861e-608b-4cd8-829d-93cdf10d833d"
   },
   "outputs": [],
   "source": [
    " # Group by data with regard to categories and ETA.\n",
    "final_data.groupby(['category', 'eta']).support_tick_id.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MIcWd2ui0CZ"
   },
   "source": [
    "> Most \"Data Recovery\" tickets are estimated by the model to be resolved in \"3 Days\".\n",
    "\n",
    "> Most \"Hardware Issues\" tickets are estimated by the model to be resovled in \"3 Days\".\n",
    "\n",
    "> Most \"Technical Isses\" tickets are estimated by the model to be resovled in \"1 Day\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "9ge5lUJiMjjP",
    "outputId": "d2cfe1ac-a741-49ba-fc34-4ffd90b28dd1"
   },
   "outputs": [],
   "source": [
    "# Final_data(output) generated by model.\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpevKeiDiVuJ"
   },
   "source": [
    "## **Actionable Insights and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aE2sFkQluiC"
   },
   "source": [
    "**Insights:**\n",
    "> A detailed company information in the prompts provide better model output.\n",
    "\n",
    "> Adjust priority levels to align with your business's actual capabilities.\n",
    "\n",
    "> Curating responses to a specific business by adjusting prompts or outputs.\n",
    "\n",
    "> Adjust or expand categories to match your business's support needs. \n",
    "\n",
    "> Overall, The model's estimation of resolution times aligns with real-world scenarios.\n",
    "\n",
    "**Recommendations:**\n",
    "> Fine-tune the model with your company's data or profile for an improved performance.\n",
    "\n",
    "> Adjust \"priority\" of support tickets to reflect priorities the business can actually facilitate.\n",
    "\n",
    "> Need to evaluate on the format of responses with regard to the mail/response delivery methods.\n",
    "\n",
    "> Require a thorough test of the model with actual data before implementation."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "47720fca238f4068901cb2c9d0b5d886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ba79b450f12494a901b3c42e3b46609": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "756fd6ded4f24c83800c007c5c05745e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "831283f977ef4f159a1210f2f48b02f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5e31abeba5a4b0a812d80d063d7313f",
      "placeholder": "",
      "style": "IPY_MODEL_4ba79b450f12494a901b3c42e3b46609",
      "value": "mistral-7b-instruct-v0.2.Q6_K.gguf:100%"
     }
    },
    "8f0551fc12b544ddb62ca4a4c0112caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a55f6b647d874c799e9ef7dcd4ade305",
      "max": 5942065440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d159ee51bca14573bad77dea32b885f7",
      "value": 5942065440
     }
    },
    "95b7bcbdc30244049555c2b415ba1ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_831283f977ef4f159a1210f2f48b02f7",
       "IPY_MODEL_8f0551fc12b544ddb62ca4a4c0112caf",
       "IPY_MODEL_ec226f1976e44fba83663baa01c9b03a"
      ],
      "layout": "IPY_MODEL_47720fca238f4068901cb2c9d0b5d886"
     }
    },
    "a55f6b647d874c799e9ef7dcd4ade305": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d159ee51bca14573bad77dea32b885f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3c2fa17a93e42a3b6440e38c3630c35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec226f1976e44fba83663baa01c9b03a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_756fd6ded4f24c83800c007c5c05745e",
      "placeholder": "",
      "style": "IPY_MODEL_d3c2fa17a93e42a3b6440e38c3630c35",
      "value": "5.94G/5.94G[00:35&lt;00:00,247MB/s]"
     }
    },
    "f5e31abeba5a4b0a812d80d063d7313f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
